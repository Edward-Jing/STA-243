{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train = pd.read_csv(\"train.data.csv\")\n",
    "test = pd.read_csv(\"test.data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract useful variables\n",
    "X_train = train[['bedrooms','bathrooms', 'sqft_living', 'sqft_lot']].to_numpy()\n",
    "X_test = test[['bedrooms','bathrooms', 'sqft_living', 'sqft_lot']].to_numpy()\n",
    "Y_train = train['price'].to_numpy().reshape(-1,1)\n",
    "Y_test = test['price'].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add interaction\n",
    "X_train = np.append(X_train, (X_train[:,0]*X_train[:,1]).reshape(-1,1),axis=1)\n",
    "X_test = np.append(X_test, (X_test[:,0]*X_test[:,1]).reshape(-1,1),axis=1)\n",
    "# Data standardization.\n",
    "# Since our data is standardized, there is no need to include intercept term.\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0)\n",
    "Y_train_mean = np.mean(Y_train)\n",
    "Y_train_std = np.std(Y_train)\n",
    "\n",
    "X1_train = (X_train-X_train_mean)/X_train_std\n",
    "X1_test = (X_test-X_train_mean)/X_train_std\n",
    "Y1_train = (Y_train-Y_train_mean)/Y_train_std\n",
    "Y1_test = (Y_test-Y_train_mean)/Y_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\\\n",
    "We use the formulae $\\hat{\\beta}=(X^T X)^{-1}X^T Y$, $R_2=1-\\frac{SSE}{SSTO}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(X, Y, X1, Y1):\n",
    "    beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "    SSE_train = np.sum((Y-X.dot(beta))**2)\n",
    "    SSTO_train = np.sum((Y-np.mean(Y))**2)\n",
    "    R2_train = 1 - SSE_train/SSTO_train\n",
    "    SSE_test = np.sum((Y1-X1.dot(beta))**2)\n",
    "    SSTO_test = np.sum((Y1-np.mean(Y1))**2)\n",
    "    R2_test = 1 - SSE_test/SSTO_test\n",
    "    return beta, R2_train, R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model is Y=80832.98912-59296.95658*X1+3681.6562*X2+316.68573*X3-0.42674*X4.\n",
      "R2 on train set is 0.51011.\n",
      "R2 on test set is 0.50499.\n"
     ]
    }
   ],
   "source": [
    "beta1, R2_train1, R2_test1 = OLS(X1_train[:,:-1], Y1_train, X1_test[:,:-1], Y1_test)\n",
    "intercept = Y_train_mean-np.sum(np.squeeze(beta1) * X_train_mean[:-1]/X_train_std[:-1])*Y_train_std\n",
    "coef = np.squeeze(beta1)/X_train_std[:-1]*Y_train_std\n",
    "print(\"Our model is Y={0}{1}*X1+{2}*X2+{3}*X3{4}*X4.\".format(np.round(intercept,5),np.round(coef[0],5),np.round(coef[1],5),np.round(coef[2],5),np.round(coef[3],5)))\n",
    "print(\"R2 on train set is {0}.\\nR2 on test set is {1}.\".format(np.round(R2_train1,5),np.round(R2_test1,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price for Bill Gats's house is 15436769.538$\n"
     ]
    }
   ],
   "source": [
    "fancy = pd.read_csv(\"fancyhouse.csv\")\n",
    "fancy_matrix = (fancy[['bedrooms','bathrooms', 'sqft_living', 'sqft_lot']].to_numpy()-X_train_mean[:-1])/X_train_std[:-1]\n",
    "fancy_predict = fancy_matrix.dot(beta1)*Y_train_std + Y_train_mean\n",
    "print(\"Predicted price for Bill Gats's house is {}$\".format(np.round(fancy_predict[0,0],3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think this price is okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model is Y=320752.74798-128706.40872*X1-111008.86939*X2+308.72484*X3-0.42458*X4+33753.60514*X1*X2.\n",
      "R2 on train set is 0.51735.\n",
      "R2 on test set is 0.51054.\n"
     ]
    }
   ],
   "source": [
    "beta2, R2_train2, R2_test2 = OLS(X1_train, Y1_train, X1_test, Y1_test)\n",
    "intercept1 = Y_train_mean-np.sum(np.squeeze(beta2)*X_train_mean/X_train_std)*Y_train_std\n",
    "coef1 = np.squeeze(beta2)/X_train_std*Y_train_std\n",
    "print(\"Our model is Y={0}{1}*X1{2}*X2+{3}*X3{4}*X4+{5}*X1*X2.\".format(np.round(intercept1,5),np.round(coef1[0],5),np.round(coef1[1],5),np.round(coef1[2],5),np.round(coef1[3],5),np.round(coef1[4],5)))\n",
    "print(\"R2 on train set is {0}.\\nR2 on test set is {1}.\".format(np.round(R2_train2,5),np.round(R2_test2,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descend(X, Y, stepsize, epsilon=1e-8):\n",
    "    _, p = X.shape\n",
    "    XTX = X.T.dot(X)\n",
    "    XTY = X.T.dot(Y)\n",
    "    beta = np.random.randn(p,1)\n",
    "    i = 0\n",
    "    while 1:\n",
    "        g = XTX.dot(beta)-XTY\n",
    "        if np.linalg.norm(g) < epsilon:\n",
    "            break\n",
    "        i = i + 1\n",
    "        beta = beta - stepsize*g\n",
    "    print(\"Using {} iteractions to converge.\".format(i))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 135 iteractions to converge.\n",
      "Using 1409 iteractions to converge.\n"
     ]
    }
   ],
   "source": [
    "# Choose stepsize according to L and mu.\n",
    "# Since this problem is strongly convex, L can be the max eigenvalue while mu can be the minimal eigenvalue\n",
    "# learning rate is 2/(lambda_min+lambda_max)\n",
    "lamda1 = np.linalg.eig(X1_train[:,:-1].T.dot(X1_train[:,:-1]))[0]\n",
    "lamda2 = np.linalg.eig(X1_train.T.dot(X1_train))[0]\n",
    "np.random.seed(2022)\n",
    "beta3 = gradient_descend(X1_train[:,:-1],Y1_train,stepsize=2/(lamda1[0]+lamda1[-1]))\n",
    "beta4 = gradient_descend(X1_train,Y1_train,stepsize=2/(lamda2[0]+lamda2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta for (a) using matrix operation: [-0.15147017  0.00773629  0.7918328  -0.04514359]\n",
      "Beta for (a) using gradient descent: [-0.15147017  0.00773629  0.7918328  -0.04514359]\n",
      "Beta for (c) using matrix operation: [-0.32877205 -0.23326364  0.77192759 -0.04491517  0.38964848]\n",
      "Beta for (c) using gradient descent: [-0.32877205 -0.23326364  0.77192759 -0.04491517  0.38964848]\n"
     ]
    }
   ],
   "source": [
    "# We can see they are almost the same.\n",
    "print(\"Beta for (a) using matrix operation: {}\".format(np.squeeze(beta1)))\n",
    "print(\"Beta for (a) using gradient descent: {}\".format(np.squeeze(beta3)))\n",
    "print(\"Beta for (c) using matrix operation: {}\".format(np.squeeze(beta2)))\n",
    "print(\"Beta for (c) using gradient descent: {}\".format(np.squeeze(beta4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descend(X, Y, stepsize, max_epoch):\n",
    "    n, p = X.shape\n",
    "    beta = np.random.randn(p)\n",
    "    iter = 0\n",
    "    with trange(max_epoch) as pbar:\n",
    "        for i in pbar:\n",
    "            indice = np.random.permutation(n)\n",
    "            for j in range(n):\n",
    "                idx = indice[j]\n",
    "                g = -2*X[idx]*(Y[idx]-np.dot(beta,X[idx]))\n",
    "                beta = beta - g*stepsize/(iter+1)\n",
    "                iter += 1\n",
    "            if i % 1 == 0:\n",
    "                MSE = np.mean((Y[:,0]-X.dot(beta))**2)\n",
    "                pbar.set_description(\"MSE={}\".format(np.round(MSE,5)))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSE=3.15989: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:16<00:00, 12.42it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "n = X_train.shape[0]\n",
    "beta5 = stochastic_gradient_descend(X1_train[:,:-1],Y1_train,stepsize=1e-2,max_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSE=0.48265: 100%|██████████| 500/500 [02:15<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "beta6 = stochastic_gradient_descend(X1_train,Y1_train,stepsize=1e-5,max_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta for (a) using matrix operation: \n",
      "[-0.15147017  0.00773629  0.7918328  -0.04514359]\n",
      "Beta for (a) using sgd: \n",
      "[-0.15070764  0.00874859  0.7927156  -0.04433098]\n",
      "Beta for (c) using matrix operation: \n",
      "[-0.32877205 -0.23326364  0.77192759 -0.04491517  0.38964848]\n",
      "Beta for (c) using sgd: \n",
      "[-0.32410012 -0.22732823  0.77209111 -0.04496272  0.3810138 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Beta for (a) using matrix operation: \\n{}\".format(np.squeeze(beta1)))\n",
    "print(\"Beta for (a) using sgd: \\n{}\".format(np.squeeze(beta5)))\n",
    "print(\"Beta for (c) using matrix operation: \\n{}\".format(np.squeeze(beta2)))\n",
    "print(\"Beta for (c) using sgd: \\n{}\".format(np.squeeze(beta6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(X, Y, beta):\n",
    "    SSE = np.sum((Y-X.dot(beta.reshape(-1,1)))**2)\n",
    "    SSTO = np.sum((Y-np.mean(Y))**2)\n",
    "    return 1 - SSE/SSTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for SGD is:\n",
      "Model without interaction train 0.51011, test 0.50501\n",
      "Model with interaction train 0.51735, test 0.51055\n"
     ]
    }
   ],
   "source": [
    "R2_train_sgd = R2(X1_train[:,:-1],Y1_train,beta5)\n",
    "R2_test_sgd = R2(X1_test[:,:-1],Y1_test,beta5)\n",
    "R2_train_int_sgd = R2(X1_train,Y1_train,beta6)\n",
    "R2_test_int_sgd = R2(X1_test,Y1_test,beta6)\n",
    "print(\"R2 for SGD is:\\nModel without interaction train {0}, test {1}\\nModel with interaction train {2}, test {3}\".format(np.round(R2_train_sgd,5),np.round(R2_test_sgd,5),np.round(R2_train_int_sgd,5),np.round(R2_test_int_sgd,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e57da381150c32bc445a617f5277ea2102eb0088f85f33ec3bf81d0c63bfe54"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
